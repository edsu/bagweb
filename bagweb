#!/bin/bash

# TODO: make sure wget and bagit.py are installed

url=$1
name=$2
date=`date '+%Y-%m-%d'`
working_dir=`pwd`
bag_dir=$working_dir/$name
log=$working_dir/$name.log

mkdir $bag_dir
cd $bag_dir

echo
echo "Crawling $url"
wget --output-file $log --warc-file $name --warc-cdx --mirror --page-requisites --html-extension --convert-links --wait 1 --execute robots=off --no-parent $url 2>/dev/null

if type "sf" > /dev/null 2>&1; then
  sf -csv -hash sha1 -z $name.warc.gz > $name.csv
fi

mirror_dir=`ls -d */`
mirror_dir=${mirror_dir%/} # strip trailing slash
tar cfz $mirror_dir.tar.gz $mirror_dir
rm -rf $mirror_dir

cd $working_dir
bagit.py --log $log --external-description "wget capture of $url created by $USER on $date" $bag_dir

echo
echo "Finished, see $log for details."
echo
echo "You may want to record additional provenance in $bag_dir/bag-info.txt"
echo
